{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from nnet import CRNN\n",
    "#from pl_trainer import SEDTask4_2021\n",
    "import pytorch_lightning as pl\n",
    "from MT_trainer import CoSMo_benchmark\n",
    "from utils.encoder import ManyHotEncoder\n",
    "from utils.utils import batched_decode_preds\n",
    "import scipy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import h5py\n",
    "from IPython.display import Audio\n",
    "from processing.sampler import ConcatDatasetBatchSampler\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import speechbrain as sb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.datasets import ConcatDatasetUrban, HDF5_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config/sed.yaml\", \"r\") as f: #try to use sed_hear/ sed_bis previous\n",
    "    conf = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../config/taxonomy_SONYC.yaml\", \"r\") as f:\n",
    "    taxonomy_sn = yaml.safe_load(f)\n",
    "\n",
    "with open(f\"../config/taxonomy_SINGA-PURA.yaml\", \"r\") as f:\n",
    "    taxonomy_sgp = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "taxonomy_coarse_sn = taxonomy_sn[\"coarse\"]\n",
    "taxonomy_fine_sn = taxonomy_sn[\"fine\"]\n",
    "taxonomy_coarse_sgp = taxonomy_sgp[\"coarse\"]\n",
    "taxonomy_fine_sgp = taxonomy_sgp[\"fine\"]\n",
    "\n",
    "encoder_fine_sn = ManyHotEncoder(\n",
    "    taxonomy_sn,\n",
    "    use_taxo_fine=True,\n",
    "    audio_len=conf[\"data\"][\"audio_max_len\"],\n",
    "    frame_len=conf[\"features\"][\"n_filters\"],\n",
    "    frame_hop=conf[\"features\"][\"hop_length\"],\n",
    "    net_pooling=conf[\"data\"][\"net_subsample\"],\n",
    "    fs=conf[\"data\"][\"fs\"],\n",
    ")\n",
    "encoder_coarse_sn = ManyHotEncoder(\n",
    "    taxonomy_sn,\n",
    "    use_taxo_fine=False,\n",
    "    audio_len=conf[\"data\"][\"audio_max_len\"],\n",
    "    frame_len=conf[\"features\"][\"n_filters\"],\n",
    "    frame_hop=conf[\"features\"][\"hop_length\"],\n",
    "    net_pooling=conf[\"data\"][\"net_subsample\"],\n",
    "    fs=conf[\"data\"][\"fs\"],\n",
    ")\n",
    "encoder_fine_sgp = ManyHotEncoder(\n",
    "    taxonomy_sgp,\n",
    "    use_taxo_fine=True,\n",
    "    audio_len=conf[\"data\"][\"audio_max_len\"],\n",
    "    frame_len=conf[\"features\"][\"n_filters\"],\n",
    "    frame_hop=conf[\"features\"][\"hop_length\"],\n",
    "    net_pooling=conf[\"data\"][\"net_subsample\"],\n",
    "    fs=conf[\"data\"][\"fs\"],\n",
    ")\n",
    "encoder_coarse_sgp = ManyHotEncoder(\n",
    "    taxonomy_sgp,\n",
    "    use_taxo_fine=False,\n",
    "    audio_len=conf[\"data\"][\"audio_max_len\"],\n",
    "    frame_len=conf[\"features\"][\"n_filters\"],\n",
    "    frame_hop=conf[\"features\"][\"hop_length\"],\n",
    "    net_pooling=conf[\"data\"][\"net_subsample\"],\n",
    "    fs=conf[\"data\"][\"fs\"],\n",
    ")\n",
    "encoder = encoder_coarse_sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGAPURA_train_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_train\"], \"SINGA-PURA\", encoder\n",
    ")\n",
    "SONYC_train_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_train\"], \"SONYC\", encoder\n",
    ")\n",
    "SINGAPURA_val_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_val\"], \"SINGA-PURA\", encoder\n",
    ")\n",
    "unlabelled_SINGAPURA_train_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_train\"],\n",
    "    \"unlabelled_SINGA-PURA\",\n",
    "    encoder,\n",
    ")\n",
    "SONYC_val_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_val\"], \"SONYC\", encoder\n",
    ")\n",
    "SINGAPURA_test_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_test\"], \"SINGA-PURA\", encoder\n",
    ")\n",
    "SONYC_test_set = HDF5_dataset(\n",
    "    conf[\"data\"][\"root_path\"] + conf[\"data\"][\"hdf5_test\"], \"SONYC\", encoder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Concat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoSMo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
