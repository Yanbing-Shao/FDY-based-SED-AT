{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35957520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorboard_reducer as tbr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd2b9176",
   "metadata": {},
   "source": [
    "## Save tensorboard logs as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11904e10-68ca-41ae-9820-a6e876611aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d, parent_key=\"\", sep=\"_\"):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ab7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"../experiments/2021_baseline/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a841d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_df(df_name, condition):\n",
    "    global_metric_df = pd.DataFrame()\n",
    "    params_df = pd.DataFrame()\n",
    "    for dir_path in root_path.rglob(\"version_*\"):\n",
    "        csv_path = dir_path / \"test_metrics.csv\"\n",
    "\n",
    "        if not os.path.exists(str(dir_path) + \"/hparams.yaml\"):\n",
    "            continue\n",
    "        with open(str(dir_path) + \"/hparams.yaml\") as f:\n",
    "            conf = yaml.safe_load(f)\n",
    "            conf.update({\"a version id\": str(dir_path)[-2:]})\n",
    "            flatten_conf = flatten(conf)\n",
    "            flatten_conf = {\n",
    "                k: str(v) for k, v in flatten_conf.items() if not k.startswith(\"data\")\n",
    "            }\n",
    "        try:\n",
    "            events_dict = tbr.load_tb_events(\n",
    "                [str(dir_path)], handle_dup_steps=\"keep-first\"\n",
    "            )\n",
    "        except AssertionError:\n",
    "            continue\n",
    "        test_metrics = {}\n",
    "        for k, df in events_dict.items():\n",
    "            if not condition(k):\n",
    "                continue\n",
    "            if \"obj_metric\" in k or \"loss\" in k:\n",
    "                scale_factor = 1\n",
    "            else:\n",
    "                scale_factor = 100\n",
    "\n",
    "            test_metrics[k.rsplit(\"/\")[1].lower()] = (\n",
    "                df.to_numpy().squeeze() * scale_factor\n",
    "            )\n",
    "\n",
    "        metrics_df = pd.DataFrame(test_metrics, index=[conf[\"experiment_name\"]])\n",
    "        metrics_df.to_csv(\n",
    "            dir_path / \"test_metrics.csv\", float_format=\"%.2self.labelsself.labelsf\"\n",
    "        )\n",
    "        global_metric_df = pd.concat([global_metric_df, metrics_df])\n",
    "        params_df = pd.concat(\n",
    "            [params_df, pd.DataFrame(flatten_conf, index=[conf[\"experiment_name\"]])]\n",
    "        )\n",
    "    global_metric_df = global_metric_df.sort_index()\n",
    "    params_df = params_df.sort_index()\n",
    "    global_metric_df.to_csv(root_path / (df_name + \"_metrics.csv\"), float_format=\"%.2f\")\n",
    "    params_df.to_csv(root_path / \"params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26822f75-29a2-427a-88a4-926c8dbe5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_name = [\n",
    "    (\"all\", lambda k: (k.startswith(\"Test\"))),\n",
    "    (\"AP\", lambda k: (k.startswith(\"Test\")) and \"ap\" in k),\n",
    "    (\"AP__micro\", lambda k: (k.startswith(\"Test\")) and \"ap_micro\" in k),\n",
    "    (\"AP_macro\", lambda k: (k.startswith(\"Test\")) and \"ap_macro\" in k),\n",
    "    (\"micro\", lambda k: (k.startswith(\"Test\")) and \"micro\" in k),\n",
    "    (\"macro\", lambda k: (k.startswith(\"Test\")) and \"macro\" in k),\n",
    "    (\"weak\", lambda k: (k.startswith(\"Test\")) and \"weak\" in k),\n",
    "    (\"strong\", lambda k: (k.startswith(\"Test\")) and \"strong\" in k),\n",
    "    (\"monoph\", lambda k: (k.startswith(\"Test\")) and \"monoph\" in k),\n",
    "    (\"lowpolyph\", lambda k: (k.startswith(\"Test\")) and \"lowpolyph\" in k),\n",
    "    (\"highpolyph\", lambda k: (k.startswith(\"Test\")) and \"highpolyph\" in k),\n",
    "    (\"near\", lambda k: (k.startswith(\"Test\")) and (\"near\" in k)),\n",
    "    (\"far\", lambda k: (k.startswith(\"Test\")) and (\"far\" in k)),\n",
    "    (\"proximity\", lambda k: (k.startswith(\"Test\")) and (\"near\" in k or \"far\" in k)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc49cb7-c92b-431d-ae30-f21a8b1cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, condition in condition_name:\n",
    "    output_df(name, condition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoSMo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
